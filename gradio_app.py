import gradio as gr
from PIL import Image
import numpy as np
import cv2
import math
from imgcraft import Editor

# ===================================================================
# KH·ªûI T·∫†O EDITOR (Phi√™n b·∫£n ·ªïn ƒë·ªãnh, kh√¥ng t·∫£i tr∆∞·ªõc)
# ===================================================================
print("Initializing Gradio App...")
# T·∫°o m·ªôt instance Editor "r·ªóng". C√°c m√¥ h√¨nh s·∫Ω ƒë∆∞·ª£c t·∫£i trong h√†m process.
comfyui_editor = Editor()
print("ComfyUI Editor is ready.")


# ===================================================================
# C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH
# ===================================================================
def resize_image(image_pil, target_width, target_height):
    original_width, original_height = image_pil.size
    width_ratio = target_width / original_width
    height_ratio = target_height / original_height
    ratio = min(width_ratio, height_ratio)
    new_width = int(original_width * ratio)
    new_height = int(original_height * ratio)
    return image_pil.resize((new_width, new_height), Image.Resampling.LANCZOS)

def align_images(img_edited_pil, img_original_pil):
    img_edited = cv2.cvtColor(np.array(img_edited_pil), cv2.COLOR_RGB2BGR)
    img_original = cv2.cvtColor(np.array(img_original_pil), cv2.COLOR_RGB2BGR)
    gray_edited = cv2.cvtColor(img_edited, cv2.COLOR_BGR2GRAY)
    gray_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)
    
    try:
        detector = cv2.AKAZE_create()
        kpts1, descs1 = detector.detectAndCompute(gray_edited, None)
        kpts2, descs2 = detector.detectAndCompute(gray_original, None)
        if descs1 is None or descs2 is None or len(descs1) < 4 or len(descs2) < 4:
             raise ValueError("Not enough keypoints for coarse alignment.")
        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = sorted(matcher.match(descs1, descs2), key=lambda x: x.distance)
        if len(matches) < 4:
            raise ValueError("Not enough matches for homography.")
        src_pts = np.float32([kpts1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kpts2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
        H_coarse, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        if H_coarse is None:
            raise ValueError("findHomography failed.")
    except Exception as e:
        print(f"Coarse alignment failed: {e}. Returning unaligned image.")
        return img_edited_pil

    h_orig, w_orig = img_original.shape[:2]
    aligned_cv = cv2.warpPerspective(img_edited, H_coarse, (w_orig, h_orig))
    return Image.fromarray(cv2.cvtColor(aligned_cv, cv2.COLOR_BGR2RGB))

# ===================================================================
# H√ÄM CH√çNH CHO GRADIO (Phi√™n b·∫£n ·ªïn ƒë·ªãnh, kh√¥ng d√πng yield)
# ===================================================================
def process_and_align(image_np, target_width, target_height, progress=gr.Progress()):
    # 1. T·∫£i v√† Resize ·∫£nh g·ªëc
    progress(0, desc="B∆∞·ªõc 1/3: ƒêang thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh g·ªëc...")
    original_pil = Image.fromarray(image_np)
    resized_original_pil = resize_image(original_pil, target_width, target_height)

    # 2. X·ª≠ l√Ω qua ComfyUI
    progress(0.2, desc="B∆∞·ªõc 2/3: ƒêang x·ª≠ l√Ω ·∫£nh qua ComfyUI (t·∫£i m√¥ h√¨nh + render)...")
    processed_pil = comfyui_editor.process(resized_original_pil)

    # 3. Kh·ªõp ·∫£nh ƒë√£ x·ª≠ l√Ω v·ªõi ·∫£nh g·ªëc ƒë√£ resize
    progress(0.9, desc="B∆∞·ªõc 3/3: ƒêang kh·ªõp ·∫£nh k·∫øt qu·∫£...")
    aligned_pil = align_images(processed_pil, resized_original_pil)

    progress(1.0, desc="Ho√†n th√†nh!")
    
    # TR·∫¢ V·ªÄ T·∫§T C·∫¢ C√ÅC ·∫¢NH C√ôNG M·ªòT L√öC
    return resized_original_pil, processed_pil, aligned_pil, aligned_pil

# ===================================================================
# X√ÇY D·ª∞NG GIAO DI·ªÜN GRADIO
# ===================================================================
with gr.Blocks(theme=gr.themes.Soft(), css=".gradio-container {max-width: 90% !important;}") as demo:
    gr.Markdown("# üé® Quy tr√¨nh X·ª≠ l√Ω & Kh·ªõp ·∫£nh T·ª± ƒë·ªông")
    gr.Markdown("T·∫£i l√™n ·∫£nh g·ªëc, ch·ªçn k√≠ch th∆∞·ªõc, sau ƒë√≥ ch∆∞∆°ng tr√¨nh s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω qua ComfyUI v√† kh·ªõp k·∫øt qu·∫£ v·ªõi ·∫£nh g·ªëc ƒë√£ ƒë∆∞·ª£c resize.")

    with gr.Row():
        with gr.Column(scale=1):
            input_image = gr.Image(type="numpy", label="1. T·∫£i l√™n ·∫¢nh G·ªëc")
            with gr.Accordion("T√πy ch·ªçn K√≠ch th∆∞·ªõc", open=True):
                target_width = gr.Number(label="Chi·ªÅu r·ªông T·ªëi ƒëa (pixel)", value=896)
                target_height = gr.Number(label="Chi·ªÅu cao T·ªëi ƒëa (pixel)", value=1344)
            run_button = gr.Button("üöÄ B·∫Øt ƒë·∫ßu X·ª≠ l√Ω & Kh·ªõp ·∫£nh", variant="primary")
        with gr.Column(scale=3):
            gr.Markdown("### K·∫øt qu·∫£")
            with gr.Tabs():
                with gr.TabItem("So s√°nh Tr∆∞·ªõc & Sau"):
                    gr.Markdown("So s√°nh ·∫£nh **ƒë√£ kh·ªõp** v·ªõi ·∫£nh **g·ªëc ƒë√£ resize**.")
                    with gr.Row():
                        output_original_resized = gr.Image(label="·∫¢nh G·ªëc (ƒë√£ resize)", interactive=False)
                        output_aligned = gr.Image(label="·∫¢nh Cu·ªëi c√πng (ƒë√£ kh·ªõp)", interactive=False)
                with gr.TabItem("C√°c b∆∞·ªõc Trung gian"):
                    with gr.Row():
                        output_processed = gr.Image(label="·∫¢nh sau khi qua ComfyUI (ch∆∞a kh·ªõp)", interactive=False)
                        output_aligned_2 = gr.Image(label="·∫¢nh Cu·ªëi c√πng (ƒë√£ kh·ªõp)", interactive=False)

    # C·∫≠p nh·∫≠t l·∫°i danh s√°ch outputs ƒë·ªÉ kh·ªõp v·ªõi h√†m return m·ªõi
    run_button.click(
        fn=process_and_align,
        inputs=[input_image, target_width, target_height],
        outputs=[output_original_resized, output_processed, output_aligned, output_aligned_2]
    )

if __name__ == "__main__":
    demo.launch(debug=True, share=True)
