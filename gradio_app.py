import gradio as gr
from PIL import Image
import numpy as np
import cv2
import math
from imgcraft import Editor

# ===================================================================
# KH·ªûI T·∫†O C√ÅC TH√ÄNH PH·∫¶N CH√çNH (T·∫£i m√¥ h√¨nh m·ªôt l·∫ßn)
# ===================================================================
print("Initializing Gradio App...")
try:
    comfyui_editor = Editor()
    print("ComfyUI Editor is ready.")
except Exception as e:
    print(f"Fatal error during Editor initialization: {e}")
    comfyui_editor = None

# ===================================================================
# C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH
# ===================================================================
def resize_image(image_pil, target_width, target_height):
    original_width, original_height = image_pil.size
    width_ratio = target_width / original_width
    height_ratio = target_height / original_height
    ratio = min(width_ratio, height_ratio)
    new_width = int(original_width * ratio)
    new_height = int(original_height * ratio)
    return image_pil.resize((new_width, new_height), Image.Resampling.LANCZOS)

def align_images(img_edited_pil, img_original_pil):
    # Chuy·ªÉn ƒë·ªïi PIL -> OpenCV BGR
    img_edited = cv2.cvtColor(np.array(img_edited_pil), cv2.COLOR_RGB2BGR)
    img_original = cv2.cvtColor(np.array(img_original_pil), cv2.COLOR_RGB2BGR)

    # B∆∞·ªõc 1: CƒÉn ch·ªânh Th√¥
    gray_edited = cv2.cvtColor(img_edited, cv2.COLOR_BGR2GRAY)
    gray_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)
    
    try:
        detector = cv2.AKAZE_create()
        kpts1, descs1 = detector.detectAndCompute(gray_edited, None)
        kpts2, descs2 = detector.detectAndCompute(gray_original, None)
        
        if descs1 is None or descs2 is None or len(descs1) < 4 or len(descs2) < 4:
             raise ValueError("Not enough keypoints/descriptors found for coarse alignment.")

        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = sorted(matcher.match(descs1, descs2), key=lambda x: x.distance)
        
        if len(matches) < 4:
            raise ValueError("Not enough matches for homography estimation.")

        src_pts = np.float32([kpts1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kpts2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
        
        H_coarse, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        if H_coarse is None:
            raise ValueError("findHomography failed in coarse alignment.")

    except Exception as e:
        print(f"Coarse alignment failed: {e}")
        # N·∫øu cƒÉn th√¥ th·∫•t b·∫°i, tr·∫£ v·ªÅ ·∫£nh ch∆∞a kh·ªõp ƒë·ªÉ ng∆∞·ªùi d√πng th·∫•y
        return img_edited_pil

    h_orig, w_orig = img_original.shape[:2]
    aligned_cv = cv2.warpPerspective(img_edited, H_coarse, (w_orig, h_orig))

    # Chuy·ªÉn ƒë·ªïi l·∫°i OpenCV BGR -> PIL
    return Image.fromarray(cv2.cvtColor(aligned_cv, cv2.COLOR_BGR2RGB))


# ===================================================================
# H√ÄM CH√çNH CHO GRADIO
# ===================================================================
def process_and_align(image_np, target_width, target_height, progress=gr.Progress()):
    if comfyui_editor is None:
        raise gr.Error("Editor kh√¥ng ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ki·ªÉm tra log Colab.")
    
    # 1. T·∫£i v√† Resize ·∫£nh g·ªëc
    progress(0, desc="B∆∞·ªõc 1/3: ƒêang thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh g·ªëc...")
    original_pil = Image.fromarray(image_np)
    resized_original_pil = resize_image(original_pil, target_width, target_height)

    # 2. X·ª≠ l√Ω qua ComfyUI
    progress(0.3, desc="B∆∞·ªõc 2/3: ƒêang x·ª≠ l√Ω ·∫£nh qua ComfyUI (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)...")
    processed_pil = comfyui_editor.process(resized_original_pil)

    # 3. Kh·ªõp ·∫£nh ƒë√£ x·ª≠ l√Ω v·ªõi ·∫£nh g·ªëc ƒë√£ resize
    progress(0.8, desc="B∆∞·ªõc 3/3: ƒêang kh·ªõp ·∫£nh k·∫øt qu·∫£...")
    aligned_pil = align_images(processed_pil, resized_original_pil)

    progress(1.0, desc="Ho√†n th√†nh!")
    return processed_pil, aligned_pil, aligned_pil # Tr·∫£ 3 ·∫£nh cho 3 output

# ===================================================================
# X√ÇY D·ª∞NG GIAO DI·ªÜN GRADIO
# ===================================================================
with gr.Blocks(theme=gr.themes.Soft(), css=".gradio-container {max-width: 90% !important;}") as demo:
    gr.Markdown("# üé® Quy tr√¨nh X·ª≠ l√Ω & Kh·ªõp ·∫£nh T·ª± ƒë·ªông")
    gr.Markdown("T·∫£i l√™n ·∫£nh g·ªëc, ch·ªçn k√≠ch th∆∞·ªõc, sau ƒë√≥ ch∆∞∆°ng tr√¨nh s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω qua ComfyUI v√† kh·ªõp k·∫øt qu·∫£ v·ªõi ·∫£nh g·ªëc ƒë√£ ƒë∆∞·ª£c resize.")

    with gr.Row():
        with gr.Column(scale=1):
            input_image = gr.Image(type="numpy", label="1. T·∫£i l√™n ·∫¢nh G·ªëc")
            with gr.Accordion("T√πy ch·ªçn K√≠ch th∆∞·ªõc", open=True):
                target_width = gr.Number(label="Chi·ªÅu r·ªông T·ªëi ƒëa (pixel)", value=896)
                target_height = gr.Number(label="Chi·ªÅu cao T·ªëi ƒëa (pixel)", value=1344)
            
            run_button = gr.Button("üöÄ B·∫Øt ƒë·∫ßu X·ª≠ l√Ω & Kh·ªõp ·∫£nh", variant="primary")

        with gr.Column(scale=3):
            gr.Markdown("### K·∫øt qu·∫£")
            with gr.Tabs():
                with gr.TabItem("So s√°nh Tr∆∞·ªõc & Sau"):
                    # Gradio kh√¥ng c√≥ image comparison t·ªët nh∆∞ Streamlit, ta d√πng 2 ·∫£nh ri√™ng
                    gr.Markdown("So s√°nh ·∫£nh **ƒë√£ kh·ªõp** v·ªõi ·∫£nh **g·ªëc ƒë√£ resize**.")
                    with gr.Row():
                        # C·∫ßn m·ªôt ·∫£nh g·ªëc ƒë·ªÉ so s√°nh, ta s·∫Ω t·∫°o n√≥ trong h√†m x·ª≠ l√Ω
                        # nh∆∞ng hi·ªán t·∫°i ƒë·ªÉ tr·ªëng, ta s·∫Ω c·∫≠p nh·∫≠t sau.
                        # ƒê√¢y l√† m·ªôt m·∫πo nh·ªè: ta s·∫Ω tr·∫£ v·ªÅ ·∫£nh ƒë√£ kh·ªõp cho c·∫£ 2 output n√†y
                        # ƒë·ªÉ so s√°nh.
                        output_aligned_for_compare = gr.Image(label="·∫¢nh G·ªëc (ƒë√£ resize)", interactive=False)
                        output_aligned = gr.Image(label="·∫¢nh Cu·ªëi c√πng (ƒë√£ kh·ªõp)", interactive=False)
                
                with gr.TabItem("C√°c b∆∞·ªõc Trung gian"):
                    with gr.Row():
                        output_processed = gr.Image(label="·∫¢nh sau khi qua ComfyUI (ch∆∞a kh·ªõp)", interactive=False)
                        output_aligned_2 = gr.Image(label="·∫¢nh Cu·ªëi c√πng (ƒë√£ kh·ªõp)", interactive=False)

    # Logic x·ª≠ l√Ω
    run_button.click(
        fn=process_and_align,
        inputs=[input_image, target_width, target_height],
        outputs=[output_processed, output_aligned, output_aligned_2]
    )

if __name__ == "__main__":
    demo.launch(debug=True, share=True)
